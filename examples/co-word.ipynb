{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:22:38.264765Z",
     "end_time": "2023-05-03T12:22:54.383577Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:22:54.413068Z",
     "end_time": "2023-05-03T12:22:56.770071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "txt_file = '먹거리_식품_안전(2017~2012).txt'\n",
    "# convert txt file to .csv file, and save it\n",
    "# we expect 20xxxxxx source text\n",
    "# splits with \\t\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def allowed_characters(string: str) -> str:\n",
    "    # returns only allowed characters and convert else to space\n",
    "    # use regex\n",
    "    return re.sub(r'[^가-힣0-9a-zA-Z]', ' ', string)\n",
    "\n",
    "skipped_line_idxs = set()\n",
    "if not os.path.exists('result.csv'):\n",
    "    print(\"processing txt file to csv file\")\n",
    "    with open(txt_file, 'r', encoding='utf-8') as txtfile:\n",
    "        total_lines = sum(1 for line in txtfile)\n",
    "    with open('result.csv', 'w', encoding='utf-8', newline='') as csv_output:\n",
    "        csv_writer = csv.writer(csv_output)\n",
    "        with open(txt_file, 'r', encoding='utf-8') as txtfile:\n",
    "            max_lines = -1 # -1 means all lines\n",
    "            cur_line = 0\n",
    "            for line in tqdm(txtfile, total=total_lines):\n",
    "                cur_line += 1\n",
    "                splits = line.split('\\t')\n",
    "                if len(splits) != 4:\n",
    "                    skipped_line_idxs.add(cur_line)\n",
    "                    continue\n",
    "                # remove \\n\n",
    "                splits[-1] = splits[-1].replace('\\n', '')\n",
    "                # remove special characters\n",
    "                splits = [allowed_characters(s) for s in splits]\n",
    "                # write to csv\n",
    "                csv_writer.writerow(splits)\n",
    "                if cur_line == max_lines:\n",
    "                    break\n",
    "    with open('skipped_line_idxs.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join((str(x) for x in skipped_line_idxs)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:22:56.771931Z",
     "end_time": "2023-05-03T12:22:56.854323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# test csv file with index 3\n",
    "with open('result.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lines = 3\n",
    "    for rows in reader:\n",
    "        try:\n",
    "            rows[3]\n",
    "        except IndexError:\n",
    "            print(lines)\n",
    "        lines-=1\n",
    "        if lines == 0:\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:22:56.854323Z",
     "end_time": "2023-05-03T12:22:56.889274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_path: None\n",
      "error_log_path: None\n",
      "log level: INFO\n"
     ]
    }
   ],
   "source": [
    "import treform as ptm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from ExampleManager import PathManager"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:22:56.897977Z",
     "end_time": "2023-05-03T12:23:12.204660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "131072"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "csv.field_size_limit(1<<21)\n",
    "# this is required to read very large csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:23:12.146176Z",
     "end_time": "2023-05-03T12:23:12.204660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-16.0.2'\n",
    "os.environ['GIT_PYTHON_GIT_EXECUTABLE'] = r'C:\\Program Files\\Git\\bin\\git.exe'\n",
    "import git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:23:12.183703Z",
     "end_time": "2023-05-03T12:23:12.738301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\박상현\\AppData\\Roaming\\Python\\Python310\\site-packages\\treform\\stopwords\n",
      "Created temporary path C:\\tmp\\clone\\122312\n",
      "Removed temporary path C:\\tmp\\clone\\122312\n",
      "parsing repo path\n"
     ]
    },
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\박상현\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\treform\\\\stopwords\\\\stopwordsKor.txt'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test packages\n",
    "from ExampleManager import PathManager\n",
    "str(PathManager('../stopwords/stopwordsKor.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:23:12.713706Z",
     "end_time": "2023-05-03T12:23:35.958642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing repo path\n"
     ]
    }
   ],
   "source": [
    "corpus = ptm.CorpusFromCSVFile('./result.csv', 3)\n",
    "pipeline = ptm.Pipeline(ptm.splitter.NLTK(),\n",
    "                        ptm.tokenizer.Word(),\n",
    "                        ptm.helper.StopwordFilter(file=str(PathManager('../stopwords/stopwordsKor.txt')))\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:23:35.956057Z",
     "end_time": "2023-05-03T12:23:38.745794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\박상현\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:24:19.581856Z",
     "end_time": "2023-05-03T12:24:24.701894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 30973/57718 [11:19:50<01:04, 416.63it/s]     "
     ]
    }
   ],
   "source": [
    "result = pipeline.processCorpus(tqdm(corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert False, \"stop here\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "documents = []\n",
    "for doc in result:\n",
    "    for sent in doc:\n",
    "        sentence = ' '.join(sent)\n",
    "        sentence = re.sub('[^A-Za-z0-9가-힣_ ]+', '', sentence)\n",
    "        sentence = sentence.strip()\n",
    "        if len(sentence) > 0:\n",
    "            documents.append(sentence)\n",
    "\n",
    "print(len(documents))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_fit = cv.fit_transform(documents)\n",
    "word_list = cv.get_feature_names()\n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "word_hist = dict(zip(word_list, count_list))\n",
    "words = []\n",
    "for word, freq in word_hist.items() :\n",
    "    for i in range(freq) :\n",
    "        words.append(word)\n",
    "co = ptm.cooccurrence.CooccurrenceManager()\n",
    "co_result, vocab = co.calculateCooccurrence(words)\n",
    "print(str(co_result))\n",
    "print(str(vocab))\n",
    "    ########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_builder = ptm.graphml.GraphMLCreator()\n",
    "# mode is either with_threshold or without_threshod\n",
    "mode = 'with_threshold'\n",
    "if mode is 'without_threshold':\n",
    "    graph_builder.createGraphML(co_result, vocab, \"test1.graphml\")\n",
    "elif mode is 'with_threshold':\n",
    "    graph_builder.createGraphMLWithThreshold(co_result, word_hist, vocab, \"test.graphml\", threshold=35.0)\n",
    "    # 이 경우에만 그림을 그려보도록 하자\n",
    "    display_limit = 50\n",
    "    graph_builder.summarize_centrality(limit=display_limit)\n",
    "    title = '동시출현 기반 그래프'\n",
    "    file_name = 'test.png'\n",
    "    graph_builder.plot_graph(title, file=file_name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "splits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:33:50.002893Z",
     "end_time": "2023-05-03T10:33:50.051114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Create a Pandas dataframe\n",
    "df = pd.DataFrame({'text': ['apple banana apple cherry cherry date']})\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(' '.join(df['text']))\n",
    "\n",
    "# Display the generated image:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:19:42.586217Z",
     "end_time": "2023-05-03T10:19:42.639665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
