{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is jupyter version of the code\n",
    "%pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treform.topic_model.pyTextMinerTopicModel import pyTextMinerTopicModel\n",
    "import treform as ptm\n",
    "import tomotopy as tp\n",
    "from tqdm import tqdm\n",
    "#import Komoran\n",
    "from treform.tokenizer import Komoran\n",
    "from ExampleManager import PathManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = ptm.Pipeline(ptm.splitter.NLTK(),\n",
    "                        Komoran(), # MeCab, Komoran, Okt, etc...\n",
    "                        # Mecab requires manual installation! try eunjeon if you can\n",
    "                        ptm.helper.POSFilter('NN*'), # Noun\n",
    "                        ptm.helper.SelectWordOnly(),\n",
    "                        ptm.helper.StopwordFilter(file=PathManager.get('../stopwords/stopwordsKor.txt'))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = ptm.CorpusFromFieldDelimitedFileWithYear(PathManager.get('../sample_data/sample_dmr_input.txt'),doc_index=2,year_index=1)\n",
    "pair_map = corpus.pair_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pipeline.processCorpus(tqdm(corpus.docs))\n",
    "text_data = []\n",
    "for doc in result:\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc in tqdm(result):\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_data[0] # example of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_model = pyTextMinerTopicModel()\n",
    "topic_number = 10\n",
    "#dominant_topic_number = 6\n",
    "#if dominant_topic_number >= topic_number:\n",
    "#    dominant_topic_number = topic_number - 1\n",
    "\n",
    "mdl=None\n",
    "#mode is either lda, dmr, hdp, infer, ct, visualize, etc\n",
    "\n",
    "mode='lda'\n",
    "label = ''\n",
    "if mode == 'lda':\n",
    "    #LDA\n",
    "    print('Running LDA')\n",
    "    label='LDA'\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    mdl=topic_model.lda_model(text_data, lda_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'dmr':\n",
    "    #DMR\n",
    "    print('Running DMR')\n",
    "    label='DMR'\n",
    "    dmr_model_name='./test.dmr.bin'\n",
    "    mdl=topic_model.dmr_model(text_data, pair_map, dmr_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hdp':\n",
    "    print('Running HDP')\n",
    "    label='HDP'\n",
    "    hdp_model_name='./test.hdp.bin'\n",
    "    mdl, topic_num=topic_model.hdp_model(text_data, hdp_model_name)\n",
    "    topic_number=topic_num\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hlda':\n",
    "    print('Running HLDA')\n",
    "    label='HLDA'\n",
    "    hlda_model_name = './test.hlda.bin'\n",
    "    mdl=topic_model.hlda_model(text_data, hlda_model_name)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'ct':\n",
    "    print('Running CT')\n",
    "    label = 'CT'\n",
    "    ct_model_name = './test.ct.bin'\n",
    "    save_file = 'D:/python_workspace/treform/topic_network.html'\n",
    "    mdl = topic_model.ct_model(text_data, ct_model_name, topic_number=topic_number, topic_network_result=save_file)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    unseen_text='아사이 베리 블루베리 비슷하다'\n",
    "    topic_model.inferLDATopicModel(lda_model_name, unseen_text)\n",
    "\n",
    "else:\n",
    "    print('No mode is selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = f'./test.{mode}.bin'\n",
    "if True: # visualize\n",
    "    if model_name == './test.lda.bin':\n",
    "        mdl = tp.LDAModel.load(model_name)\n",
    "    elif model_name == './test.dmr.bin':\n",
    "        mdl = tp.DMRModel.load(model_name)\n",
    "        visual_result_file1= './dmr_line_graph.png'\n",
    "        visual_result_file2 = './dmr_bar_graph.png'\n",
    "        topic_model.visualizeDMR(mdl,visual_result1=visual_result_file1, visual_result2=visual_result_file2)\n",
    "    elif model_name == './test.ct.bin':\n",
    "        mdl = tp.CTModel.load(model_name)\n",
    "        result_file = './topic_network.html'\n",
    "        topic_model.visualize_ct_model(mdl, topic_network_result=result_file)\n",
    "    else:\n",
    "        raise Exception(\"Cannot visualize this model {}\".format(model_name))\n",
    "\n",
    "    mdl.load(model_name)\n",
    "    # The below code extracts this dominant topic for each sentence\n",
    "    # and shows the weight of the topic and the keywords in a nicely formatted output.\n",
    "    df_topic_sents_keywords, matrix = topic_model.format_topics_sentences(topic_number=topic_number, mdl=mdl)\n",
    "\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    df_dominant_topic.head(10)\n",
    "\n",
    "    # Sometimes we want to get samples of sentences that most represent a given topic.\n",
    "    # This code gets the most exemplar sentence for each topic.\n",
    "    dist_result_file_ = './dist_doc_word_count.png'\n",
    "    #topic_model.distribution_document_word_count(df_topic_sents_keywords, df_dominant_topic, result_file=dist_result_file_)\n",
    "\n",
    "    #When working with a large number of documents,\n",
    "    # we want to know how big the documents are as a whole and by topic.\n",
    "    #Let’s plot the document word counts distribution.\n",
    "    dominant_result_file_ = './dominant_topic_word_count.png'\n",
    "    dominant_topic_number = 7\n",
    "    #topic_model.distribution_word_count_by_dominant_topic(df_dominant_topic,dominant_topic_number=dominant_topic_number, result_file=dominant_result_file_)\n",
    "\n",
    "    # Though we’ve already seen what are the topic keywords in each topic,\n",
    "    # a word cloud with the size of the words proportional to the weight is a pleasant sight.\n",
    "    # The coloring of the topics I’ve taken here is followed in the subsequent plots as well.\n",
    "    topic_cloud_result_file = './topic_word_cloud.png'\n",
    "    topic_number = mdl.k\n",
    "    #topic_model.word_cloud_by_topic(mdl, topic_number=topic_number,topic_cloud_result_file=topic_cloud_result_file)\n",
    "\n",
    "    topic_keyword_result_file = './topic_keyword.png'\n",
    "    # Let’s plot the word counts and the weights of each keyword in the same chart.\n",
    "    #topic_model.word_count_by_keywords(mdl,matrix,topic_keyword_result_file=topic_keyword_result_file, topic_number=topic_number)\n",
    "\n",
    "    topics_per_document = './topic_per_document.png'\n",
    "    #topic_model.topics_per_document(mdl, start=0, end=10, topics_per_document=topics_per_document, topic_number=topic_number)\n",
    "\n",
    "    #visualize documents by tSNE\n",
    "    #topic_model.tSNE(mdl,matrix,label,topic_number=topic_number)\n",
    "\n",
    "    visualization_file='./topic_visualization.html'\n",
    "    #topic_model.make_pyLDAVis(mdl,visualization_file=visualization_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
