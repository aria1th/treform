{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in /usr/local/python/3.10.4/lib/python3.10/site-packages (0.3.2)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from pyvis) (3.0.1)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /home/codespace/.local/lib/python3.10/site-packages (from pyvis) (3.1.2)\n",
      "Requirement already satisfied: networkx>=1.11 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from pyvis) (2.8.8)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from pyvis) (8.12.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (2.14.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.9.0)\n",
      "Requirement already satisfied: pickleshare in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (3.0.38)\n",
      "Requirement already satisfied: stack-data in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.18.2)\n",
      "Requirement already satisfied: backcall in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis) (2.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 01:30:59.320006: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 01:31:01.657121: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 01:31:01.658157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 01:31:05.957745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_path: None\n",
      "error_log_path: None\n",
      "log level: INFO\n"
     ]
    }
   ],
   "source": [
    "from treform.topic_model.pyTextMinerTopicModel import pyTextMinerTopicModel\n",
    "import treform as ptm\n",
    "import tomotopy as tp\n",
    "from tqdm import tqdm\n",
    "#import Komoran\n",
    "from treform.tokenizer import Komoran\n",
    "from ExampleManager import PathManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing repo path\n"
     ]
    }
   ],
   "source": [
    "pipeline = ptm.Pipeline(ptm.splitter.NLTK(),\n",
    "                        Komoran(),\n",
    "                        ptm.helper.POSFilter('NN*'),\n",
    "                        ptm.helper.SelectWordOnly(),\n",
    "                        ptm.helper.StopwordFilter(file=PathManager.get('../stopwords/stopwordsKor.txt'))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ptm.CorpusFromFieldDelimitedFileWithYear(PathManager.get('../sample_data/sample_dmr_input.txt'),doc_index=2,year_index=1)\n",
    "pair_map = corpus.pair_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1126/1206 [04:52<00:47,  1.68it/s]"
     ]
    }
   ],
   "source": [
    "result = pipeline.processCorpus(tqdm(corpus.docs))\n",
    "text_data = []\n",
    "for doc in result:\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1206/1206 [00:00<00:00, 7264.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(result):\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:51: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:51: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_4557/1661906077.py:51: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif mode is 'infer':\n"
     ]
    }
   ],
   "source": [
    "topic_model = pyTextMinerTopicModel()\n",
    "topic_number=10\n",
    "#dominant_topic_number = 6\n",
    "#if dominant_topic_number >= topic_number:\n",
    "#    dominant_topic_number = topic_number - 1\n",
    "\n",
    "mdl=None\n",
    "#mode is either lda, dmr, hdp, infer, ct, visualize, etc\n",
    "\n",
    "mode='lda'\n",
    "label = ''\n",
    "if mode == 'lda':\n",
    "    print('Running LDA')\n",
    "    label='LDA'\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    mdl=topic_model.lda_model(text_data, lda_model_name, topic_number)\n",
    "\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'dmr':\n",
    "    print('Running DMR')\n",
    "    label='DMR'\n",
    "    dmr_model_name='./test.dmr.bin'\n",
    "    mdl=topic_model.dmr_model(text_data, pair_map, dmr_model_name, topic_number)\n",
    "\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hdp':\n",
    "    print('Running HDP')\n",
    "    label='HDP'\n",
    "    hdp_model_name='./test.hdp.bin'\n",
    "    mdl, topic_num=topic_model.hdp_model(text_data, hdp_model_name)\n",
    "    topic_number=topic_num\n",
    "\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hlda':\n",
    "    print('Running HLDA')\n",
    "    label='HLDA'\n",
    "    hlda_model_name = './test.hlda.bin'\n",
    "    mdl=topic_model.hlda_model(text_data, hlda_model_name)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'ct':\n",
    "    print('Running CT')\n",
    "    label = 'CT'\n",
    "    ct_model_name = './test.ct.bin'\n",
    "    save_file = 'D:/python_workspace/treform/topic_network.html'\n",
    "    mdl = topic_model.ct_model(text_data, ct_model_name, topic_number=topic_number, topic_network_result=save_file)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    unseen_text='아사이 베리 블루베리 비슷하다'\n",
    "    topic_model.inferLDATopicModel(lda_model_name, unseen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open file './test.ct.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     topic_model\u001b[39m.\u001b[39mvisualizeDMR(mdl,visual_result1\u001b[39m=\u001b[39mvisual_result_file1, visual_result2\u001b[39m=\u001b[39mvisual_result_file2)\n\u001b[1;32m     10\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./test.ct.bin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     mdl \u001b[39m=\u001b[39m tp\u001b[39m.\u001b[39;49mCTModel\u001b[39m.\u001b[39;49mload(model_name)\n\u001b[1;32m     12\u001b[0m     result_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD:/python_workspace/treform/topic_network.html\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m     topic_model\u001b[39m.\u001b[39mvisualize_ct_model(mdl, topic_network_result\u001b[39m=\u001b[39mresult_file)\n",
      "\u001b[0;31mOSError\u001b[0m: cannot open file './test.ct.bin'"
     ]
    }
   ],
   "source": [
    "if mode == 'visualize':\n",
    "    model_name = './test.ct.bin'\n",
    "    if model_name == './test.lda.bin':\n",
    "        mdl = tp.LDAModel.load(model_name)\n",
    "    elif model_name == './test.dmr.bin':\n",
    "        mdl = tp.DMRModel.load(model_name)\n",
    "        visual_result_file1= '../dmr_line_graph.png'\n",
    "        visual_result_file2 = '../dmr_bar_graph.png'\n",
    "        topic_model.visualizeDMR(mdl,visual_result1=visual_result_file1, visual_result2=visual_result_file2)\n",
    "    elif model_name == './test.ct.bin':\n",
    "        mdl = tp.CTModel.load(model_name)\n",
    "        result_file = './topic_network.html'\n",
    "        topic_model.visualize_ct_model(mdl, topic_network_result=result_file)\n",
    "\n",
    "    mdl.load(model_name)\n",
    "    # The below code extracts this dominant topic for each sentence\n",
    "    # and shows the weight of the topic and the keywords in a nicely formatted output.\n",
    "    df_topic_sents_keywords, matrix = topic_model.format_topics_sentences(topic_number=topic_number, mdl=mdl)\n",
    "\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    df_dominant_topic.head(10)\n",
    "\n",
    "    # Sometimes we want to get samples of sentences that most represent a given topic.\n",
    "    # This code gets the most exemplar sentence for each topic.\n",
    "    dist_result_file_ = '../dist_doc_word_count.png'\n",
    "    #topic_model.distribution_document_word_count(df_topic_sents_keywords, df_dominant_topic, result_file=dist_result_file_)\n",
    "\n",
    "    #When working with a large number of documents,\n",
    "    # we want to know how big the documents are as a whole and by topic.\n",
    "    #Let’s plot the document word counts distribution.\n",
    "    dominant_result_file_ = '../dominant_topic_word_count.png'\n",
    "    dominant_topic_number = 7\n",
    "    #topic_model.distribution_word_count_by_dominant_topic(df_dominant_topic,dominant_topic_number=dominant_topic_number, result_file=dominant_result_file_)\n",
    "\n",
    "    # Though we’ve already seen what are the topic keywords in each topic,\n",
    "    # a word cloud with the size of the words proportional to the weight is a pleasant sight.\n",
    "    # The coloring of the topics I’ve taken here is followed in the subsequent plots as well.\n",
    "    topic_cloud_result_file = '../topic_word_cloud.png'\n",
    "    topic_number = mdl.k\n",
    "    #topic_model.word_cloud_by_topic(mdl, topic_number=topic_number,topic_cloud_result_file=topic_cloud_result_file)\n",
    "\n",
    "    topic_keyword_result_file = '../topic_keyword.png'\n",
    "    # Let’s plot the word counts and the weights of each keyword in the same chart.\n",
    "    #topic_model.word_count_by_keywords(mdl,matrix,topic_keyword_result_file=topic_keyword_result_file, topic_number=topic_number)\n",
    "\n",
    "    topics_per_document = '../topic_per_document.png'\n",
    "    #topic_model.topics_per_document(mdl, start=0, end=10, topics_per_document=topics_per_document, topic_number=topic_number)\n",
    "\n",
    "    #visualize documents by tSNE\n",
    "    #topic_model.tSNE(mdl,matrix,label,topic_number=topic_number)\n",
    "\n",
    "    visualization_file='../topic_visualization.html'\n",
    "    #topic_model.make_pyLDAVis(mdl,visualization_file=visualization_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
