{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is jupyter version of the code\n",
    "%pip install pyvis --user\n",
    "%pip install treform --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treform.topic_model.pyTextMinerTopicModel import pyTextMinerTopicModel\n",
    "import treform as ptm\n",
    "import tomotopy as tp\n",
    "from tqdm import tqdm\n",
    "#import Komoran\n",
    "from treform.tokenizer import Komoran\n",
    "from ExampleManager import PathManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus = ptm.CorpusFromFieldDelimitedFileWithYear(PathManager.get('../sample_data/sample_dmr_input.txt'),doc_index=2,year_index=1)\n",
    "\n",
    "corpus = ptm.CorpusFromFieldDelimitedFileWithYear('file.csv', doc_index= 1, year_index=0, delimiter=',')\n",
    "pair_map = corpus.pair_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(corpus.docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = ptm.Pipeline(ptm.splitter.NLTK(),\n",
    "                        Komoran(), # MeCab, Komoran, Okt, etc...\n",
    "                        # Mecab requires manual installation! try eunjeon if you can\n",
    "                        ptm.helper.POSFilter('NN*'), # Noun\n",
    "                        ptm.helper.SelectWordOnly(),\n",
    "                        ptm.helper.StopwordFilter(file=PathManager.get('../stopwords/stopwordsKor.txt'))\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pipeline.processCorpus(tqdm(corpus.docs))\n",
    "text_data = []\n",
    "for doc in result:\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc in tqdm(result):\n",
    "    new_doc = []\n",
    "    for sent in doc:\n",
    "        for _str in sent:\n",
    "            if len(_str) > 0:\n",
    "                new_doc.append(_str)\n",
    "    text_data.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_data[0] # example of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get memory size of text data\n",
    "import sys\n",
    "print(sys.getsizeof(text_data))\n",
    "# pickle if smaller than 1GB\n",
    "if sys.getsizeof(text_data) < 1<<30:\n",
    "    import pickle\n",
    "    with open('text_data.pickle', 'wb') as f:\n",
    "        pickle.dump(text_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_model = pyTextMinerTopicModel()\n",
    "topic_number = 10\n",
    "#dominant_topic_number = 6\n",
    "#if dominant_topic_number >= topic_number:\n",
    "#    dominant_topic_number = topic_number - 1\n",
    "\n",
    "mdl=None\n",
    "#mode is either lda, dmr, hdp, infer, ct, visualize, etc\n",
    "\n",
    "mode='lda'\n",
    "label = ''\n",
    "if mode == 'lda':\n",
    "    #LDA\n",
    "    print('Running LDA')\n",
    "    label='LDA'\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    mdl=topic_model.lda_model(text_data, lda_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'dmr':\n",
    "    #DMR\n",
    "    print('Running DMR')\n",
    "    label='DMR'\n",
    "    dmr_model_name='./test.dmr.bin'\n",
    "    mdl=topic_model.dmr_model(text_data, pair_map, dmr_model_name, topic_number)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hdp':\n",
    "    print('Running HDP')\n",
    "    label='HDP'\n",
    "    hdp_model_name='./test.hdp.bin'\n",
    "    mdl, topic_num=topic_model.hdp_model(text_data, hdp_model_name)\n",
    "    topic_number=topic_num\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'hlda':\n",
    "    print('Running HLDA')\n",
    "    label='HLDA'\n",
    "    hlda_model_name = './test.hlda.bin'\n",
    "    mdl=topic_model.hlda_model(text_data, hlda_model_name)\n",
    "    print('perplexity score ' + str(mdl.perplexity))\n",
    "\n",
    "elif mode == 'ct':\n",
    "    print('Running CT')\n",
    "    label = 'CT'\n",
    "    ct_model_name = './test.ct.bin'\n",
    "    save_file = 'D:/python_workspace/treform/topic_network.html'\n",
    "    mdl = topic_model.ct_model(text_data, ct_model_name, topic_number=topic_number, topic_network_result=save_file)\n",
    "\n",
    "elif mode == 'infer':\n",
    "    lda_model_name = './test.lda.bin'\n",
    "    unseen_text='아사이 베리 블루베리 비슷하다'\n",
    "    topic_model.inferLDATopicModel(lda_model_name, unseen_text)\n",
    "\n",
    "else:\n",
    "    print('No mode is selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode = 'lda'\n",
    "model_name = f'./test.{mode}.bin'\n",
    "topic_number = 10\n",
    "if locals().get('topic_model') is None:\n",
    "    topic_model = pyTextMinerTopicModel()\n",
    "\n",
    "mdl = tp.LDAModel.load(model_name)\n",
    "print(\"Model loaded\")\n",
    "mdl.load(model_name)\n",
    "# The below code extracts this dominant topic for each sentence\n",
    "# and shows the weight of the topic and the keywords in a nicely formatted output.\n",
    "df_topic_sents_keywords, matrix = pyTextMinerTopicModel().format_topics_sentences(topic_number=topic_number, mdl=mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(df_topic_sents_keywords)\n",
    "if sys.getsizeof(df_topic_sents_keywords) < 1<<30:\n",
    "    import pickle\n",
    "    with open('df_topic_sents_keywords.pickle', 'wb') as f:\n",
    "        pickle.dump(df_topic_sents_keywords, f)\n",
    "else:\n",
    "    print('df_topic_sents_keywords is too big to dump')\n",
    "# Now dump matrix if it is smaller than 1GB\n",
    "if sys.getsizeof(matrix) < 1<<30:\n",
    "    import pickle\n",
    "    with open('matrix.pickle', 'wb') as f:\n",
    "        pickle.dump(matrix, f)\n",
    "else:\n",
    "    print('matrix is too big to dump')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "def tSNE(mdl, matrix, label, topic_number=10):\n",
    "    from bokeh.plotting import figure, output_file, show\n",
    "    from bokeh.models import Label\n",
    "    from bokeh.io import output_notebook\n",
    "    import matplotlib.colors as mcolors\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "    # Array of topic weights\n",
    "    arr = pd.DataFrame(matrix).fillna(0).values\n",
    "\n",
    "    # Dominant topic number in each doc\n",
    "    topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "    # tSNE Dimension Reduction\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "    tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "    n_topics = topic_number\n",
    "    mycolors = np.array([color for name, color in matplotlib.colors.cnames.items()])\n",
    "    plot = figure(title=\"t-SNE Clustering of {} \" + label + \"Topics\".format(n_topics),\n",
    "                  width=900, height=700)\n",
    "\n",
    "    plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "\n",
    "    show(plot)\n",
    "topic_model.tSNE = tSNE # monkey patching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_topic_model(topic_model, mdl, matrix, label=''):\n",
    "    import pickle\n",
    "    with open('df_topic_sents_keywords.pickle', 'rb') as f:\n",
    "        df_topic_sents_keywords = pickle.load(f)\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    df_dominant_topic.head(10)\n",
    "\n",
    "    # Sometimes we want to get samples of sentences that most represent a given topic.\n",
    "    # This code gets the most exemplar sentence for each topic.\n",
    "    dist_result_file_ = f'./dist_doc_word_count{label}.png'\n",
    "    topic_model.distribution_document_word_count(df_topic_sents_keywords, df_dominant_topic, result_file=dist_result_file_)\n",
    "\n",
    "    #When working with a large number of documents,\n",
    "    # we want to know how big the documents are as a whole and by topic.\n",
    "    #Let’s plot the document word counts distribution.\n",
    "    dominant_result_file_ = f'./dominant_topic_word_count{label}.png'\n",
    "    dominant_topic_number = 7\n",
    "    topic_model.distribution_word_count_by_dominant_topic(df_dominant_topic,dominant_topic_number=dominant_topic_number, result_file=dominant_result_file_)\n",
    "\n",
    "    # Though we’ve already seen what are the topic keywords in each topic,\n",
    "    # a word cloud with the size of the words proportional to the weight is a pleasant sight.\n",
    "    # The coloring of the topics I’ve taken here is followed in the subsequent plots as well.\n",
    "    topic_cloud_result_file = f'./topic_word_cloud{label}.png'\n",
    "    topic_number = mdl.k\n",
    "    topic_model.word_cloud_by_topic(mdl, topic_number=topic_number,topic_cloud_result_file=topic_cloud_result_file)\n",
    "\n",
    "    topic_keyword_result_file = f'./topic_keyword{label}.png'\n",
    "    # Let’s plot the word counts and the weights of each keyword in the same chart.\n",
    "    topic_model.word_count_by_keywords(mdl,matrix,topic_keyword_result_file=topic_keyword_result_file, topic_number=topic_number)\n",
    "\n",
    "    topics_per_document = f'./topic_per_document{label}.png'\n",
    "    topic_model.topics_per_document(mdl, start=0, end=10, topics_per_document=topics_per_document, topic_number=topic_number)\n",
    "\n",
    "    #visualize documents by tSNE\n",
    "    topic_model.tSNE(mdl,matrix,'',topic_number=topic_number)\n",
    "\n",
    "    visualization_file=f'./topic_visualization{label}.html'\n",
    "    topic_model.make_pyLDAVis(mdl,visualization_file=visualization_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize(mode, topic_number, topic_model=None, return_matrix=False):\n",
    "    model_name = f'./test.{mode}.bin'\n",
    "    topic_number = 10\n",
    "    if locals().get('topic_model') is None:\n",
    "        topic_model = pyTextMinerTopicModel()\n",
    "    if model_name == './test.lda.bin':\n",
    "        mdl = tp.LDAModel.load(model_name)\n",
    "        print(\"Model loaded\")\n",
    "    elif model_name == './test.dmr.bin':\n",
    "        mdl = tp.DMRModel.load(model_name)\n",
    "        visual_result_file1= './dmr_line_graph.png'\n",
    "        visual_result_file2 = './dmr_bar_graph.png'\n",
    "        pyTextMinerTopicModel().visualizeDMR(mdl,visual_result1=visual_result_file1, visual_result2=visual_result_file2)\n",
    "    elif model_name == './test.ct.bin':\n",
    "        mdl = tp.CTModel.load(model_name)\n",
    "        result_file = './topic_network.html'\n",
    "        topic_model.visualize_ct_model(mdl, topic_network_result=result_file)\n",
    "    else:\n",
    "        raise Exception(\"Cannot visualize this model {}\".format(model_name))\n",
    "    if return_matrix:\n",
    "        df_topic_sents_keywords, matrix = pyTextMinerTopicModel().format_topics_sentences(topic_number=topic_number, mdl=mdl)\n",
    "    else:\n",
    "        matrix = None\n",
    "    return mdl, matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now dmr\n",
    "\n",
    "# load from 'text_data.pickle'\n",
    "import pickle\n",
    "with open('text_data.pickle', 'rb') as f:\n",
    "    text_data = pickle.load(f)\n",
    "corpus = ptm.CorpusFromFieldDelimitedFileWithYear('3_class_naver_news.csv', doc_index=4, year_index=0, delimiter=',')\n",
    "pair_map = corpus.pair_map\n",
    "mode = 'dmr'\n",
    "print('Running DMR')\n",
    "label='DMR'\n",
    "dmr_model_name='./test.dmr.bin'\n",
    "mdl=pyTextMinerTopicModel().dmr_model(text_data, pair_map, dmr_model_name, 10)\n",
    "print('perplexity score ' + str(mdl.perplexity))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now visualize\n",
    "model, matrix = visualize(mode, 10, mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if matrix does not exist, pickle\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "if not os.path.exists('matrix.pickle'):\n",
    "    print('matrix does not exist, pickle')\n",
    "    if sys.getsizeof(matrix) > 100000000:\n",
    "        print('matrix is too big, skip')\n",
    "    else:\n",
    "        with open('matrix.pickle', 'wb') as f:\n",
    "            pickle.dump(matrix, f)\n",
    "\n",
    "visualize_topic_model(pyTextMinerTopicModel(), mdl, matrix, label='DMR')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
